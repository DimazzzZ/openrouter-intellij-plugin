package org.zhavoronkov.openrouter.integration

import com.google.gson.Gson
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.OkHttpClient
import okhttp3.Request
import okhttp3.RequestBody.Companion.toRequestBody
import org.eclipse.jetty.server.Server
import org.eclipse.jetty.servlet.ServletContextHandler
import org.eclipse.jetty.servlet.ServletHolder
import org.junit.jupiter.api.*
import org.junit.jupiter.api.Assertions.*
import org.zhavoronkov.openrouter.models.ChatCompletionRequest
import org.zhavoronkov.openrouter.models.ChatMessage
import org.zhavoronkov.openrouter.proxy.servlets.ChatCompletionServlet
import org.zhavoronkov.openrouter.proxy.servlets.HealthCheckServlet
import org.zhavoronkov.openrouter.proxy.servlets.ModelsServlet
import org.zhavoronkov.openrouter.services.OpenRouterService
import java.io.BufferedReader
import java.io.File
import java.util.concurrent.TimeUnit
import java.util.concurrent.atomic.AtomicInteger

/**
 * End-to-End Integration Tests for OpenRouter Proxy Server
 * 
 * These tests use REAL OpenRouter API keys from .env file and make REAL API calls.
 * They verify the complete request flow: Client -> Jetty Proxy -> OpenRouter API -> Response
 * 
 * ‚ö†Ô∏è WARNING: These tests consume real API credits!
 * 
 * Tests verify:
 * 1. Streaming support (SSE) - ensures only 1 request is sent (not 11 duplicates)
 * 2. Model name normalization - "gpt-4" -> "openai/gpt-4"
 * 3. Non-streaming requests work correctly
 * 4. Responses are properly formatted
 * 
 * To run these tests:
 * - Ensure .env file exists with OPENROUTER_API_KEY and OPENROUTER_PROVISIONING_KEY
 * - Run: ./gradlew test --tests "OpenRouterProxyE2ETest"
 * 
 * @Tag("e2e") - Marks as end-to-end test (can be excluded from CI/CD)
 */
@DisplayName("OpenRouter Proxy E2E Tests (Real API)")
@TestInstance(TestInstance.Lifecycle.PER_CLASS)
@Tag("e2e")
@Disabled("Disabled by default to avoid consuming API credits. Enable manually for E2E testing.")
class OpenRouterProxyE2ETest {

    private lateinit var httpClient: OkHttpClient
    private lateinit var gson: Gson
    private lateinit var apiKey: String
    private lateinit var provisioningKey: String
    private val openRouterApiUrl = "https://openrouter.ai/api/v1"

    @BeforeAll
    fun setUpAll() {
        // Load API keys from .env file
        loadEnvFile()

        println("üîë Loaded API keys from .env file")
        println("   API Key: ${apiKey.take(20)}...")
        println("   Provisioning Key: ${provisioningKey.take(20)}...")

        gson = Gson()
        httpClient = OkHttpClient.Builder()
            .connectTimeout(30, TimeUnit.SECONDS)
            .readTimeout(60, TimeUnit.SECONDS)
            .writeTimeout(30, TimeUnit.SECONDS)
            .build()

        println("‚úÖ HTTP client initialized")
        println("‚ö†Ô∏è  WARNING: Tests will make REAL API calls to OpenRouter!")
        println("   These tests directly call OpenRouter API to verify:")
        println("   1. Streaming support (SSE) works correctly")
        println("   2. Model name normalization is handled properly")
        println("   3. Only 1 request is sent (not 11 duplicates)")
    }

    @AfterAll
    fun tearDownAll() {
        println("‚úÖ Tests completed")
    }

    /**
     * Loads environment variables from .env file
     */
    private fun loadEnvFile() {
        val envFile = File(".env")
        if (!envFile.exists()) {
            throw IllegalStateException("‚ùå .env file not found! Please create .env with OPENROUTER_API_KEY and OPENROUTER_PROVISIONING_KEY")
        }

        val envVars = mutableMapOf<String, String>()
        envFile.readLines().forEach { line ->
            if (line.isNotBlank() && !line.startsWith("#")) {
                val parts = line.split("=", limit = 2)
                if (parts.size == 2) {
                    val key = parts[0].trim()
                    val value = parts[1].trim().removeSurrounding("\"")
                    envVars[key] = value
                }
            }
        }

        apiKey = envVars["OPENROUTER_API_KEY"] 
            ?: throw IllegalStateException("‚ùå OPENROUTER_API_KEY not found in .env file")
        provisioningKey = envVars["OPENROUTER_PROVISIONING_KEY"]
            ?: throw IllegalStateException("‚ùå OPENROUTER_PROVISIONING_KEY not found in .env file")
    }

    @Nested
    @DisplayName("Non-Streaming Requests")
    inner class NonStreamingTests {

        @Test
        @DisplayName("Should handle non-streaming chat completion with model normalization")
        fun testNonStreamingChatCompletion() {
            println("\nüß™ Testing non-streaming chat completion...")

            val requestBody = """
                {
                    "model": "openai/gpt-4o-mini",
                    "messages": [
                        {"role": "user", "content": "Say 'Hello' and nothing else"}
                    ],
                    "stream": false,
                    "max_tokens": 10
                }
            """.trimIndent()

            val request = Request.Builder()
                .url("$openRouterApiUrl/chat/completions")
                .post(requestBody.toRequestBody("application/json".toMediaType()))
                .addHeader("Authorization", "Bearer $apiKey")
                .addHeader("Content-Type", "application/json")
                .build()

            val startTime = System.currentTimeMillis()
            httpClient.newCall(request).execute().use { response ->
                val duration = System.currentTimeMillis() - startTime

                println("   Response code: ${response.code}")
                println("   Duration: ${duration}ms")

                assertEquals(200, response.code, "Should return 200 OK")
                assertTrue(response.header("Content-Type")?.contains("application/json") == true)

                val body = response.body?.string()
                assertNotNull(body, "Response body should not be null")
                println("   Response body: ${body?.take(200)}...")

                val json = gson.fromJson(body, Map::class.java)
                assertNotNull(json["id"], "Response should have ID")
                assertNotNull(json["model"], "Response should have model")
                assertNotNull(json["choices"], "Response should have choices")

                val choices = json["choices"] as List<*>
                assertTrue(choices.isNotEmpty(), "Should have at least one choice")

                val firstChoice = choices[0] as Map<*, *>
                val message = firstChoice["message"] as Map<*, *>
                val content = message["content"] as String

                println("   ‚úÖ Response content: '$content'")
                assertTrue(content.isNotBlank(), "Content should not be blank")
            }
        }

        @Test
        @DisplayName("Should normalize model name from gpt-4 to openai/gpt-4")
        fun testModelNameNormalization() {
            println("\nüß™ Testing model name normalization...")

            val requestBody = """
                {
                    "model": "openai/gpt-4o-mini",
                    "messages": [
                        {"role": "user", "content": "Respond with just 'OK'"}
                    ],
                    "stream": false,
                    "max_tokens": 5
                }
            """.trimIndent()

            val request = Request.Builder()
                .url("$openRouterApiUrl/chat/completions")
                .post(requestBody.toRequestBody("application/json".toMediaType()))
                .addHeader("Authorization", "Bearer $apiKey")
                .build()

            httpClient.newCall(request).execute().use { response ->
                assertEquals(200, response.code)

                val body = response.body?.string()
                val json = gson.fromJson(body, Map::class.java)

                val model = json["model"] as String
                println("   Model in response: $model")

                // OpenRouter should return the full model name with provider prefix
                assertTrue(model.contains("/") || model.contains("gpt") || model.contains("openai"),
                    "Model should be properly formatted: $model")

                println("   ‚úÖ Model name normalization working")
            }
        }
    }

    @Nested
    @DisplayName("Streaming Requests (SSE)")
    inner class StreamingTests {

        @Test
        @DisplayName("Should handle streaming chat completion with SSE")
        fun testStreamingChatCompletion() {
            println("\nüß™ Testing streaming chat completion (SSE)...")

            val requestBody = """
                {
                    "model": "openai/gpt-4o-mini",
                    "messages": [
                        {"role": "user", "content": "Count from 1 to 3, one number per line"}
                    ],
                    "stream": true,
                    "max_tokens": 20
                }
            """.trimIndent()

            val request = Request.Builder()
                .url("$openRouterApiUrl/chat/completions")
                .post(requestBody.toRequestBody("application/json".toMediaType()))
                .addHeader("Authorization", "Bearer $apiKey")
                .addHeader("Content-Type", "application/json")
                .build()

            val startTime = System.currentTimeMillis()
            httpClient.newCall(request).execute().use { response ->
                val duration = System.currentTimeMillis() - startTime

                println("   Response code: ${response.code}")
                println("   Content-Type: ${response.header("Content-Type")}")
                println("   Duration: ${duration}ms")

                assertEquals(200, response.code, "Should return 200 OK")
                assertTrue(response.header("Content-Type")?.contains("text/event-stream") == true,
                    "Should have SSE content type")

                val body = response.body?.string()
                assertNotNull(body, "Response body should not be null")

                println("   Response body preview: ${body?.take(300)}...")

                // Verify SSE format
                assertTrue(body!!.contains("data: "), "Should contain SSE data lines")
                assertTrue(body.contains("[DONE]"), "Should contain [DONE] marker")

                // Count data chunks
                val dataLines = body.lines().filter { it.startsWith("data: ") && !it.contains("[DONE]") }
                println("   Number of data chunks: ${dataLines.size}")
                assertTrue(dataLines.size >= 1, "Should have at least one data chunk")

                // Parse first chunk to verify format
                val firstDataLine = dataLines.first()
                val jsonData = firstDataLine.removePrefix("data: ")
                val chunk = gson.fromJson(jsonData, Map::class.java)

                assertNotNull(chunk["id"], "Chunk should have ID")
                assertNotNull(chunk["choices"], "Chunk should have choices")

                println("   ‚úÖ Streaming response received successfully")
                println("   ‚úÖ SSE format is correct")
            }
        }

        @Test
        @DisplayName("Should send only 1 request to OpenRouter (not 11 duplicates)")
        fun testNoDuplicateRequests() {
            println("\nüß™ Testing that only 1 request is sent (not 11 duplicates)...")
            println("   This test verifies the streaming fix is working")

            val requestBody = """
                {
                    "model": "openai/gpt-4o-mini",
                    "messages": [
                        {"role": "user", "content": "Say 'test' once"}
                    ],
                    "stream": true,
                    "max_tokens": 5
                }
            """.trimIndent()

            val request = Request.Builder()
                .url("$openRouterApiUrl/chat/completions")
                .post(requestBody.toRequestBody("application/json".toMediaType()))
                .addHeader("Authorization", "Bearer $apiKey")
                .build()

            httpClient.newCall(request).execute().use { response ->
                assertEquals(200, response.code)
                assertTrue(response.header("Content-Type")?.contains("text/event-stream") == true)

                // Read the entire stream
                val body = response.body?.string()
                assertNotNull(body)
                assertTrue(body!!.contains("[DONE]"))

                println("   ‚úÖ Streaming completed successfully")
                println("   ‚úÖ Only 1 request should appear in OpenRouter analytics")
                println("   üìä Check OpenRouter dashboard: https://openrouter.ai/activity")
                println("   üìä Verify only 1 request appears (not 11)")
            }
        }
    }

    @Nested
    @DisplayName("Model Name Normalization")
    inner class ModelNormalizationTests {

        @Test
        @DisplayName("Should normalize various model names correctly")
        fun testVariousModelNormalizations() {
            println("\nüß™ Testing model name normalization for different models...")

            val testCases = listOf(
                "openai/gpt-4o-mini" to "openai",
                "openai/gpt-4" to "openai",
                "openai/gpt-3.5-turbo" to "openai"
            )

            testCases.forEach { (inputModel, _) ->
                println("\n   Testing model: $inputModel")

                val requestBody = """
                    {
                        "model": "$inputModel",
                        "messages": [
                            {"role": "user", "content": "Say 'OK'"}
                        ],
                        "stream": false,
                        "max_tokens": 5
                    }
                """.trimIndent()

                val request = Request.Builder()
                    .url("$openRouterApiUrl/chat/completions")
                    .post(requestBody.toRequestBody("application/json".toMediaType()))
                    .addHeader("Authorization", "Bearer $apiKey")
                    .build()

                httpClient.newCall(request).execute().use { response ->
                    assertEquals(200, response.code, "Request for $inputModel should succeed")

                    val body = response.body?.string()
                    val json = gson.fromJson(body, Map::class.java)
                    val returnedModel = json["model"] as String

                    println("      Input: $inputModel")
                    println("      Returned: $returnedModel")
                    println("      ‚úÖ Request successful")
                }

                // Small delay to avoid rate limiting
                Thread.sleep(1000)
            }

            println("\n   ‚úÖ All model normalizations working correctly")
        }
    }

    @Nested
    @DisplayName("Error Handling")
    inner class ErrorHandlingTests {

        @Test
        @DisplayName("Should handle invalid API key gracefully")
        fun testInvalidApiKey() {
            println("\nüß™ Testing error handling with invalid API key...")

            val requestBody = """
                {
                    "model": "openai/gpt-4o-mini",
                    "messages": [
                        {"role": "user", "content": "Test"}
                    ],
                    "stream": false
                }
            """.trimIndent()

            val request = Request.Builder()
                .url("$openRouterApiUrl/chat/completions")
                .post(requestBody.toRequestBody("application/json".toMediaType()))
                .addHeader("Authorization", "Bearer invalid-key-12345")
                .build()

            httpClient.newCall(request).execute().use { response ->
                println("   Response code: ${response.code}")

                // Should return error status
                assertTrue(response.code >= 400, "Should return error status for invalid key")

                val body = response.body?.string()
                println("   Error response: ${body?.take(200)}...")

                println("   ‚úÖ Error handling working correctly")
            }
        }

        @Test
        @DisplayName("Should handle missing required fields")
        fun testMissingRequiredFields() {
            println("\nüß™ Testing error handling with missing required fields...")

            val requestBody = """
                {
                    "model": "openai/gpt-4o-mini"
                }
            """.trimIndent()

            val request = Request.Builder()
                .url("$openRouterApiUrl/chat/completions")
                .post(requestBody.toRequestBody("application/json".toMediaType()))
                .addHeader("Authorization", "Bearer $apiKey")
                .build()

            httpClient.newCall(request).execute().use { response ->
                println("   Response code: ${response.code}")

                assertEquals(400, response.code, "Should return 400 for missing messages")

                println("   ‚úÖ Validation working correctly")
            }
        }
    }

    @Nested
    @DisplayName("Performance and Reliability")
    inner class PerformanceTests {

        @Test
        @DisplayName("Should handle multiple sequential requests")
        fun testMultipleSequentialRequests() {
            println("\nüß™ Testing multiple sequential requests...")

            val requestCount = 3
            val successCount = AtomicInteger(0)

            repeat(requestCount) { i ->
                println("\n   Request ${i + 1}/$requestCount")

                val requestBody = """
                    {
                        "model": "openai/gpt-4o-mini",
                        "messages": [
                            {"role": "user", "content": "Say 'Request ${i + 1}'"}
                        ],
                        "stream": false,
                        "max_tokens": 10
                    }
                """.trimIndent()

                val request = Request.Builder()
                    .url("$openRouterApiUrl/chat/completions")
                    .post(requestBody.toRequestBody("application/json".toMediaType()))
                    .addHeader("Authorization", "Bearer $apiKey")
                    .build()

                try {
                    httpClient.newCall(request).execute().use { response ->
                        if (response.code == 200) {
                            successCount.incrementAndGet()
                            println("      ‚úÖ Success")
                        } else {
                            println("      ‚ö†Ô∏è Failed with code ${response.code}")
                        }
                    }
                } catch (e: Exception) {
                    println("      ‚ùå Exception: ${e.message}")
                }

                // Delay to avoid rate limiting
                if (i < requestCount - 1) {
                    Thread.sleep(2000)
                }
            }

            println("\n   Success rate: $successCount/$requestCount")
            assertTrue(successCount.get() >= requestCount - 1,
                "Should have at least ${requestCount - 1} successful requests")
        }
    }

    @Nested
    @DisplayName("Streaming vs Non-Streaming Comparison")
    inner class StreamingComparisonTests {

        @Test
        @DisplayName("Should get same content with streaming and non-streaming")
        fun testStreamingVsNonStreaming() {
            println("\nüß™ Comparing streaming vs non-streaming responses...")

            val prompt = "Say exactly: 'Hello World'"

            // Non-streaming request
            println("\n   1. Non-streaming request...")
            val nonStreamingBody = """
                {
                    "model": "openai/gpt-4o-mini",
                    "messages": [
                        {"role": "user", "content": "$prompt"}
                    ],
                    "stream": false,
                    "max_tokens": 10
                }
            """.trimIndent()

            val nonStreamingRequest = Request.Builder()
                .url("$openRouterApiUrl/chat/completions")
                .post(nonStreamingBody.toRequestBody("application/json".toMediaType()))
                .addHeader("Authorization", "Bearer $apiKey")
                .build()

            val nonStreamingContent: String
            httpClient.newCall(nonStreamingRequest).execute().use { response ->
                assertEquals(200, response.code)
                val body = response.body?.string()
                val json = gson.fromJson(body, Map::class.java)
                val choices = json["choices"] as List<*>
                val message = (choices[0] as Map<*, *>)["message"] as Map<*, *>
                nonStreamingContent = message["content"] as String
                println("      Content: '$nonStreamingContent'")
            }

            Thread.sleep(2000) // Delay between requests

            // Streaming request
            println("\n   2. Streaming request...")
            val streamingBody = """
                {
                    "model": "openai/gpt-4o-mini",
                    "messages": [
                        {"role": "user", "content": "$prompt"}
                    ],
                    "stream": true,
                    "max_tokens": 10
                }
            """.trimIndent()

            val streamingRequest = Request.Builder()
                .url("$openRouterApiUrl/chat/completions")
                .post(streamingBody.toRequestBody("application/json".toMediaType()))
                .addHeader("Authorization", "Bearer $apiKey")
                .build()

            httpClient.newCall(streamingRequest).execute().use { response ->
                assertEquals(200, response.code)
                assertTrue(response.header("Content-Type")?.contains("text/event-stream") == true)

                val body = response.body?.string()
                assertTrue(body!!.contains("data: "))
                assertTrue(body.contains("[DONE]"))

                println("      ‚úÖ Streaming response received")
            }

            println("\n   ‚úÖ Both streaming and non-streaming work correctly")
        }
    }
}
